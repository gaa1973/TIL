10/28

# Docer を使用した場合の環境

🌐 ① 通常の開発環境（Docker なし）

```
[PC]
 ├─ Node.js（バージョン管理必要）
 ├─ React 開発環境
 ├─ Express サーバー
 └─ Supabase（外部クラウド or ローカルDB）
      • 問題点：
            ○ Node.jsのバージョンやライブラリの違いで「動く／動かない」が出やすい
            ○ 複数人で開発すると環境差が問題になる
            ○ ローカルに DB を置く場合、設定が面倒

🐳 ② Docker を使った開発環境

[Docker Compose]
 ├─ react-app (コンテナ)
 │    └─ Node.js + React
 ├─ express-api (コンテナ)
 │    └─ Node.js + Express
 └─ postgres-db (コンテナ)
      └─ PostgreSQL (SupabaseのDB互換)
      • メリット：
            - 環境が完全に統一される
                  § 「誰がどのPCでやっても同じ環境」
            - 複数サービスをまとめて起動できる
                  § docker-compose up だけで React + Express + DB が全部起動
            - 本番環境との整合性
                  § Dockerイメージはそのまま本番サーバーに移行可能
            - Supabase をローカルで使う場合も、Dockerで PostgreSQL を簡単に用意できる
```

⚙️ ③ Docker Compose のイメージ例

```
version: '3'
services:
  react-app:
    build: ./frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
    depends_on:
      - express-api
express-api:
    build: ./backend
    ports:
      - "4000:4000"
    volumes:
      - ./backend:/app
    environment:
      - DATABASE_URL=postgres://postgres:password@postgres-db:5432/mydb
    depends_on:
      - postgres-db
postgres-db:
    image: postgres:15
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: mydb
    ports:
      - "5432:5432"
      • react-app：Reactフロントエンド
      • express-api：Expressバックエンド
      • postgres-db：ローカルのDB（SupabaseのPostgreSQL互換）
```

✅ まとめ - Docker なしでも開発は可能（特に Vercel を使うなら不要） - チーム開発や複数サービスを同時に扱う場合は Docker が便利 - Docker を使うと「環境差によるトラブル」がほぼゼロになる - Supabase の DB をローカルで使う場合も Docker が役立つ

## Docker 起動エラーについて

Progate で docker compose up -d が動かなかった件
・Docker 　 Desktop を以前にインストールしていたが、起動していなかった

今の状況（要点） - Windows 側の Docker Desktop と Engine は稼働中（あなたの以前の出力で確認済み）。 - WSL 側でも docker コマンドが動作するようになったとのこと（OK）。
もしこれでプロジェクトを起動したいなら（このワークスペースにある compose.yaml を使う想定）、WSL のプロジェクトディレクトリで次を実行してください：

# docker コマンド

コンテナをビルドしてバックグラウンドで起動（推奨）：
docker compose up -d --build
ログを確認したい場合：
docker compose logs -f

### または特定サービスだけ

docker compose logs -f api

コンテナ一覧を確認：
docker compose ps

### または全コンテナ

docker ps -a

停止（停止してイメージは残す）：
docker compose stop

完全に停止してネットワーク・ボリュームなども削除する：
docker compose down

次のオプション（必要なら）
• e2e テストやローカル開発をすぐ試したければ、起動してからブラウザで指定のポート（compose.yaml に従う）にアクセスしてください。compose のサービス名やポートが分からなければ教えてください — 私が compose.yaml を読んで該当ポート/サービス名を教えます。
• 起動でエラーが出たら、docker compose logs の出力を貼ってください。原因を解析して修正案を出します。
続けるか選んでください： 1. そのまま docker compose up -d --build を実行してほしい（実行後のログを貼る） 2. 私に compose.yaml の中身を確認して起動手順／公開ポートを教えてほしい 3. 代替案（WSL 内直接 docker エンジン等）が必要
やりたい番号を教えてください。

# Dockerfile とは

Dockerfile とは、Docker イメージの作成手順が記載されたテキストファイルです。
Dockerfile には、ベースとして利用する Docker イメージに対して「このパッケージをインストールせよ」「このファイルを追加せよ」といった命令を記述します。 命令を記述することにより、既存の Docker イメージをカスタマイズして独自の Docker イメージを作成できます。
通常 Dockerfile は Dockerfile というファイル名で作成します。例えば、Docker を使ってみようのケースでは、api フォルダに以下のような Dockerfile が用意されていました。

FROM node:22.13.1-bullseye-slim

WORKDIR /app

COPY package-lock.json ./
COPY ./api/package.json ./
RUN npm install

ENTRYPOINT [ "bash", "./entrypoint.sh" ]

## 主要な命令

命令 概要

- FROM ベースイメージを指定
- COPY ファイル、ディレクトリをコピー
- RUN コマンドを実行
- WORKDIR 作業ディレクトリを変更
- CMD コンテナ起動時に実行するコマンドを指定（実行時に上書き可能）
- ENTRYPOINT コンテナ起動時に実行するコマンドを指定（基本的に必ず実行）
- FROM ベースイメージを指定します。
  FROM [--platform=<platform>] <image> [AS <name>]

Dockerfile を作成するには、まずベースとなるイメージを FROM 命令で指定する必要がある。
「基本的にどんなイメージでも指定できますが、軽量でセキュアなイメージを作成するためにも、要件を満たす必要最小限のイメージを用いることを心がけましょう」

- -COPY ファイル、ディレクトリをコピーします。
  COPY [OPTIONS] <src> ... <dest>
  COPY [OPTIONS] ["<src>", ... "<dest>"]
  類似する命令として ADD がありますが、ほとんどのユースケースでは、シンプルさとセキュリティの観点から COPY コマンドが利用されます。
  ADD と COPY の違い、使い分けについては、詳しくは ADD or COPY を参考にしてください。
- RUN コマンドを実行します。
  Shell form:
  RUN [OPTIONS] <command> ...
  Exec form:
  RUN [OPTIONS] [ "<command>", ... ]
  よくあるユースケースとしては、Debian 系のベースイメージが指定された場合に、apt-get を用いてパッケージをインストールします。

  curl コマンドをインストールする例

  RUN apt-get update && apt-get install -y curl
  RUN コマンドのベストプラクティスは RUN を参考にしてください。

- WORKDIR 作業ディレクトリを変更します。
  WORKDIR /path/to/workdir
  WORKDIR /app のように、コマンドを実行する際の作業ディレクトリを設定します。
  特定のディレクトリで何回もコマンドを実行したい場合、毎回 cd を実行するよりも WORKDIR 命令で作業ディレクトリを指定する方が効率的です。
  指定するパスは絶対パスであることが推奨されます。詳しくは WORKDIR を参考にしてください。
- CMD コンテナ起動時に実行するコマンドを指定します。
  Shell form:

  CMD command param1 param2

  Exec form:

  CMD ["executable","param1","param2"]

  Exec form, as default parameters to ENTRYPOINT

  CMD ["param1","param2"]
  nginx の例では、以下の CMD 命令が指定されていました。
  CMD ["nginx", "-g", "daemon off;"]
  これまで docker container run 実行時、起動時に実行するコマンドを指定しなくても nginx の Web サーバーが立ち上がったのは、この命令が記述されていたためです。
  ユーザーが明示的にコマンドを記述した場合は、CMD 命令は無視されます。
  以下は nginx のコンテナで、nginx サーバーを起動するデフォルトの命令を無視して echo を実行する例です。

  docker container run --rm --name nginx_override -it nginx:latest echo 'CMD instruction has been overridden'

  ENTRYPOINT コンテナ起動時に実行するコマンドを指定します。

  Shell form:

  ENTRYPOINT command param1 param2

  Exec form:

  ENTRYPOINT ["executable", "param1", "param2"]
  CMD と同じく、コンテナ起動時に実行するコマンドを指定します。
  CMD との違いとしては、CMD があくまでデフォルトのコマンドの指定でありユーザーの上書きが可能であるのに対し、ENTRYPOINT は基本的に上書きできません。
  ENTRYPOINT はコンテナ起動時に必ず実行したいコマンドがある場合に利用すると良いでしょう。

  docker コマンドについて
  具体的な docker コマンドを学ぶ前に、docker コマンドの基本的な構造を覚えておきましょう。 docker コマンドは、「何を」「どうする」といった形式で整理されています。
  例えば、Docker コンテナを実行するコマンドは container を run する ので、 docker container run と書きます。docker コマンドを読み解く際にはこの構造を把握しておくと役立つでしょう。
  実は docker には新コマンドと旧コマンドがあり、先ほど紹介した書き方は新コマンドのものです。旧コマンドでは、例えば先ほどのコンテナ実行のコマンドを docker run と書きます。この場合「何を」実行するか不明瞭で、パッと見ただけでは何を run する コマンドなのかが分かりません。
  書籍や記事によっては旧コマンドを使用していることもありますが、Progate Path のタスクでは基本的に新コマンドを使用します。

  Docker コマンド一覧 #Docker - Qiita

## 1. ボリュームを作成する

まずはマウントを設定するためのボリュームを作成する

docker volume create docker_storage_volume
docker volume ls | grep docker_storage_volume
ボリュームを作成するには、docker volume create コマンドを使用します。ボリュームを作成する際は名前を付ける必要があるため、今回は docker volume create docker_storage_volume としました。
また、作成済みのボリューム一覧を表示するコマンドは docker volume ls です。ただ、環境によっては大量のボリュームが出力されてしまうため、先程の例では docker_storage_volume という文字列を持つ情報のみを grep で絞り込んでいます。

# コンテナを実行する

Docker コンテナのデータについて
Docker の基本を学ぼう タスクでも学んだように、Docker コンテナは Docker イメージを元に作成されます。ただし、コンテナ内でファイルを作成・変更しても、それらのデータはイメージに保存されるわけではありません。
そのため、コンテナを破棄すると、それまでに作成・変更したデータはすべて失われてしまいます。

# ボリュームマウントについて

ボリュームマウントは、 Docker Engine が管理するディレクトリ領域にデータを保存し、それを共有する 仕組みです。ボリュームマウントは、主にデータベースやアプリケーションが生成するログなど、コンテナ内で生成・更新されるデータを永続化する際に用いられます。
以下の手順で、データベースの情報をボリュームマウントで作成した領域に保存し、コンテナを破棄・再構築した際にデータがどのような状態になるか、確認してみましょう。

# バインドマウントについて学ぼう

バインドマウントは、ホストマシンにある任意のディレクトリやファイルを、コンテナ内にマウントする 仕組みです。バインドマウントは、主に package.json などの設定ファイルや、アプリケーションのソースコードをホストマシンとコンテナ間で共有する際に用いられます。
以下の手順で Express.js のソースコードをホストマシンとコンテナ間で共有し、ホストマシンでファイルを更新する場合とコンテナ内でファイルを作成する場合、それぞれでどのような状態になるか確認してみましょう。 1. ホストマシンの src ディレクトリをバインドマウントした状態でコンテナを起動する 2. ホストマシンでファイルを更新し、コンテナに反映されるかを確認する 3. コンテナ内でファイルを作成し、ホストマシンに反映されるかを確認する

## まとめ: Docker におけるデータの扱いとデータの永続化方法について

### Docker のデータ保持について

Docker コンテナは、破棄するとコンテナ内で作成・変更したファイルが失われます。一見不便に思えますが、この設計思想のおかげで可搬性が向上し、システム全体のスケール性が向上するメリットがあります。
データを永続化するための方法
データを永続化する方法として、 ボリュームマウント と バインドマウント という 2 つのマウント方式について学びました。それぞれのマウント方式は以下のような特性を持っています。
マウント方式 データの管理場所 使用用途
ボリュームマウント Docker Engine データベース、ログ等
バインドマウント ホストマシン 設定ファイルやソースコードの共有
両者の主な違いは、「データの管理場所」と「使用用途」にあります。目的に応じて適切なマウント方法を選択できると、Docker を使った開発・運用の幅が広がるはずです。
詳細な情報を知りたい方は Docker 公式ドキュメントの volumes や Bind mounts を確認してみましょう。

## compose.yaml に複数のコンテナを定義しよう

Docker Compose を使えば、複数のコンテナを 1 つの設定ファイルでまとめて管理できます。その設定ファイルが compose.yaml です。
ここからは、実際にアプリケーションの開発環境を構築するための compose.yaml を作成します。データベース・API・フロントエンドといった複数のサービスを定義し、それらを連携させる構成にしていきましょう。

## ompose.yaml でよく使う基本オプション

compose.yaml では、以下のオプションがよく使われます。ハンズオンを始める前に各オプションの概要を確認しておきましょう。
オプション 説明
services 各サービス（コンテナ）を定義するブロックであることを宣言します
image 使用する Docker イメージを指定します
build Dockerfile からイメージをビルドする際に使用します
ports ホスト・コンテナ間で紐づけるポート番号を指定します
volumes データの永続化が必要な際、ボリュームの方式などを指定します
environment コンテナ内で使用する環境変数を定義します
depends_on 他サービスとの起動順を制御する際に使用します
command イメージ起動時に実行するコマンドを指定します
Docker 公式の Compose file reference を参照

### YAML の書き方と注意点

YAML は人間に読みやすいシンプルなフォーマットですが、記述する際は以下の点に注意する必要があります。
• インデントは 半角スペース 2 つ で、 タブ文字は使用しない こと
• キーと値の間は : + 半角スペース であること
○ 例）image: mysql:8.4.4
また、配列を表現するときは以下のように - を使って記述します。

>

まとめ：Docker Compose の概要とメリットについて
最後に、このタスクで学んだ Docker Compose の概要と、そのメリットを整理しておきましょう。
Docker Compose の概要
Docker Compose は、複数のコンテナで構成されるアプリケーションを 1 つの設定ファイルにまとめて定義し、一括で起動・管理できるツールです。通常、 Docker Desktop に標準で含まれているため、追加のインストール等なくすぐに利用できます。
Docker Compose を使うことで、個別にコンテナを操作する手間を省き、開発チーム全体で共通の環境を簡単に構築できるようになります。
Docker Compose を使うメリット

- コンテナごとに個別のコマンドを実行する必要がなくなり、作業ミスのリスクを低減できること
- ボリュームやネットワークなどの周辺リソースも一括で管理できるため、コンテナ間の連携をスムーズにできること
- サービス間の起動順序を制御できるため、安定した環境構築を実現できること
- compose.yaml ファイルを共有することで、チーム全体で同じ環境を再現できること
  Docker Compose は実務でも広く使われているツールです。複数のサービスを組み合わせた構成は一見複雑に見えますが、1 つずつ仕組みを理解して再現性の高い開発環境を構築できるようにしておきましょう。

## Docker におけるキャッシュの仕組み

Docker は、 Dockerfile に記述された命令（RUN、COPY など）を 上から順に 処理していきます。
各命令の結果は レイヤー（差分） として記録され、前回ビルドを実行した時点からレイヤーに変更がなければ、前回の結果をキャッシュから再利用できます。
ただし、 ある命令でキャッシュが無効になると、それ以降の命令も全て再実行される という点には注意が必要です。

変更されやすい命令は後ろに、変更されにくい命令は前に書く ことで、キャッシュを最大限に活用できます。

## .dockerignore とは

.dockerignore は、Docker イメージのビルド時に ビルドコンテキストから除外したいファイルやディレクトリを指定するための設定ファイル です。
Docker は、 docker build コマンドを実行したとき次の 2 ステップでファイルを読み込みます。 1. .dockerignore ファイルの内容を読み取る 2. 指定されたビルドコンテキストのファイルを読み込む
このとき、 .dockerignore が適切に設定されていないと、以下のような問題が発生します。
• node_modules などのサイズが大きいディレクトリがそのまま読み込まれ、 ビルド時間が長くなる
• .env などの機密ファイルが読み込まれてしまい、 セキュリティリスクが高まる
.dockerignore を活用することで、これらの不要なファイルをビルド処理から除外できます。

#　容量不足の対処方法
仮想ディスクの場所を特定する手順
仮想ディスクファイル（ext4.vhdx）の正確なパスは、Windows ストアからインストールした Ubuntu やその他のディストリビューションによって異なります。
以下の手順で、正確なパスを確認してください。

## Step 1: パスの前半（%LOCALAPPDATA%）を確認する

まず、コマンドプロンプトやエクスプローラーのアドレスバーに以下を入力します。
%LOCALAPPDATA%\Packages
• %LOCALAPPDATA% は、C:\Users\あなたのユーザー名\AppData\Local を意味する環境変数です。

## Step 2: 目的のディストリビューションフォルダを探す

Packages フォルダの中に、以下のような非常に長い名前のフォルダが多数並んでいます。この中から、あなたが利用している WSL ディストリビューション（例：Ubuntu）を示すフォルダを探します。
ディストリビューション フォルダ名の例（省略記号...の正体）
Ubuntu CanonicalGroupLimited.Ubuntu... のような長い名前のフォルダ
Debian TheDebianProject.Debian... のような長い名前のフォルダ

## Step 3: ext4.vhdx の場所を特定する

目的のフォルダを見つけたら、その中をたどります。
C:\Users\あなたのユーザー名\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu...\LocalState\ext4.vhdx
この**「CanonicalGroupLimited.Ubuntu...」**の部分が、あなたがご質問された ... の正体です。

## Step 4: diskpart で使うパスを作成する

diskpart でパスを指定する際は、この完全なパスをダブルクォーテーションで囲んで使用する必要があります。
【実行例（Windows PowerShell の場合）】
Bash

### 圧縮前に WSL をシャットダウン

wsl --shutdown
diskpart
diskpart で以下のコマンドを入力します（パスはご自身の環境に合わせて修正してください）。
コード スニペット

select vdisk file="C:\Users\shino\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu...\LocalState\ext4.vhdx

## Step 1: Docker/WSL 関連のプロセスを完全に強制終了させる（最重要）

PowerShell またはコマンドプロンプトを**「管理者として実行」**し、以下のコマンドを順番に入力してください。 1. 再度 WSL をシャットダウン（念押し）:
Bash

wsl --shutdown 2. Docker 関連のプロセスを強制終了: Docker Desktop のバックグラウンドサービスを終了させます。
Bash

taskkill /f /im com.docker.backend.exe
taskkill /f /im Vmmem.exe
○ Vmmem.exe は WSL の仮想メモリプロセスです。これが終了すると、ファイルロックが解除されます。
Step 2: diskpart による圧縮の実行
上記のプロセス強制終了後、同じ「管理者として実行」した PowerShell で、再度 diskpart を起動し、圧縮を試みます。
Bash

diskpart
diskpart が起動したら、以下のコマンドを順に入力します（パスは絶対に省略しないでください）。
コード スニペット

#### 圧縮対象の仮想ディスクファイルを選択

select vdisk file="C:\Users\shino\AppData\Local\Docker\wsl\disk\docker_data.vhdx"

#### 仮想ディスクを圧縮

compact vdisk

#### 仮想ディスクを閉じる

detach vdisk

#### diskpart を終了

## exit 3. Docker の再起動

圧縮が完了したら、Windows のスタートメニューから Docker Desktop を再起動してください。
ポイント: ファイルロックを解除するためには、手動でのプロセス強制終了（taskkill）が不可欠です。この最終ステップで、容量解放を成功させましょう
